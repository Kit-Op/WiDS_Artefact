# WiDS_Artefact
Code for medical heath data regression ML proving high bias regardless model type. Data-set is confidential.

Artefact_Thesis_Studies_ML.ipynb computes different by use of different regression models, techniques and optimisation frameworks looks wheather it is possible to maintain data of all persons represented in the with the societal bias unchanged. 

It uses traditional model frameworks, neural network solutions, and parameter optimisation techniques in order to acheave as high variance as possible while maintaining the bias within the data it self. 

The aim of the study was to prove biases existance in real world data and measure it's impact on ML models. Study managed to prove statistical significance in different values and their overall impact on the target variable. Study managed to prove biases presence by measuring skewness of data. The sparsity of such data and complexity of the issue could not give accurate prediction while maintaining the integrity of the data, thus considering it unethical to use as an administrative tool within healthcare sector. 


Azure Files for Model 1:
  MLmodel
  conda.yaml
  model.pkl
  model_test.py
  python_env.yaml
  requirements.txt


Artefact link colab:
https://colab.research.google.com/drive/1I9VuaUf2QuWIUNbzeUy8ZNphlZfgZjad?usp=sharing

Main artefact link consists of the optimisation, and general algorithm analysts. There are some neural networks, that where made to branch for columns and herarchical among other techniques used,that did not manage tu successfully include while select, the main features. Thus not all of it is included in the main paper. 

Additional, related to feature extraction and why they where not applicable:
https://colab.research.google.com/drive/1ktmgOLaL3Qwx3LFEF1LjcF67EjFsOQZQ?usp=sharing


Statistiscs, significance among other metrics where calculated on local machine. If additional materials or code samples are needed. Contact the supervisor or author. 


Visual Studio Code's Co-pilot and ChatGPT was used to debugg the code. WiDS project ensured lectures every week, that built on the project and data science skills as well Medium articles where read on daily bases to create understanding before working with inclusivity. However, there is no one thing that was used to butild this. Most code snipits, data adaptation etc. took weeks and longer, as different versions wehre built and tested. 

There are very many imports in the main notebook, but they have been necesarry as not always the colab recognised the imports, further up, and thus needed to be re-imported continuously.






  
